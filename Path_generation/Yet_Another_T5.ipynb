{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de485a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.optimization import  Adafactor \n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "574d74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/Path_gen/mid2namefull.pickle', 'rb') as f:\n",
    "    mid2name = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "985f9031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47236138"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mid2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6114238",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('../Data/Path_gen/data_train_t5.csv', index_col=[0]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe000c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>topic</th>\n",
       "      <th>sub</th>\n",
       "      <th>ans</th>\n",
       "      <th>target_text</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>venus</td>\n",
       "      <td>namesake</td>\n",
       "      <td>named after</td>\n",
       "      <td>venus</td>\n",
       "      <td>what is venus named for?</td>\n",
       "      <td>symbols.namesake.named_after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rome</td>\n",
       "      <td>namesake</td>\n",
       "      <td>named after</td>\n",
       "      <td>romulus and remus</td>\n",
       "      <td>what does the name rome mean?</td>\n",
       "      <td>symbols.namesake.named_after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rome</td>\n",
       "      <td>namesake</td>\n",
       "      <td>named after</td>\n",
       "      <td>romulus and remus</td>\n",
       "      <td>where did the name rome come from?</td>\n",
       "      <td>symbols.namesake.named_after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>austin</td>\n",
       "      <td>namesake</td>\n",
       "      <td>named after</td>\n",
       "      <td>stephen f. austin</td>\n",
       "      <td>what does the name austin stand for?</td>\n",
       "      <td>symbols.namesake.named_after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>melbourne</td>\n",
       "      <td>namesake</td>\n",
       "      <td>named after</td>\n",
       "      <td>william lamb, 2nd viscount melbourne</td>\n",
       "      <td>where does the name melbourne come from?</td>\n",
       "      <td>symbols.namesake.named_after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24913</th>\n",
       "      <td>leonardo da vinci</td>\n",
       "      <td>inventor</td>\n",
       "      <td>inventions</td>\n",
       "      <td>aerial screw</td>\n",
       "      <td>what were some inventions of leonardo da vinci?</td>\n",
       "      <td>law.inventor.inventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24914</th>\n",
       "      <td>leonardo da vinci</td>\n",
       "      <td>inventor</td>\n",
       "      <td>inventions</td>\n",
       "      <td>armored car</td>\n",
       "      <td>what were some inventions of leonardo da vinci?</td>\n",
       "      <td>law.inventor.inventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24915</th>\n",
       "      <td>roger bacon</td>\n",
       "      <td>inventor</td>\n",
       "      <td>inventions</td>\n",
       "      <td>magnifying glass</td>\n",
       "      <td>who is roger bacon inventor of?</td>\n",
       "      <td>law.inventor.inventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24916</th>\n",
       "      <td>charles babbage</td>\n",
       "      <td>inventor</td>\n",
       "      <td>inventions</td>\n",
       "      <td>difference engine</td>\n",
       "      <td>what did charles babbage create in the 1800s?</td>\n",
       "      <td>law.inventor.inventions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24917</th>\n",
       "      <td>charles babbage</td>\n",
       "      <td>inventor</td>\n",
       "      <td>inventions</td>\n",
       "      <td>analytical engine</td>\n",
       "      <td>what did charles babbage create in the 1800s?</td>\n",
       "      <td>law.inventor.inventions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22132 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    head     topic          sub  \\\n",
       "0                  venus  namesake  named after   \n",
       "1                   rome  namesake  named after   \n",
       "2                   rome  namesake  named after   \n",
       "3                 austin  namesake  named after   \n",
       "4              melbourne  namesake  named after   \n",
       "...                  ...       ...          ...   \n",
       "24913  leonardo da vinci  inventor   inventions   \n",
       "24914  leonardo da vinci  inventor   inventions   \n",
       "24915        roger bacon  inventor   inventions   \n",
       "24916    charles babbage  inventor   inventions   \n",
       "24917    charles babbage  inventor   inventions   \n",
       "\n",
       "                                        ans  \\\n",
       "0                                     venus   \n",
       "1                         romulus and remus   \n",
       "2                         romulus and remus   \n",
       "3                         stephen f. austin   \n",
       "4      william lamb, 2nd viscount melbourne   \n",
       "...                                     ...   \n",
       "24913                          aerial screw   \n",
       "24914                           armored car   \n",
       "24915                      magnifying glass   \n",
       "24916                     difference engine   \n",
       "24917                     analytical engine   \n",
       "\n",
       "                                           target_text  \\\n",
       "0                             what is venus named for?   \n",
       "1                        what does the name rome mean?   \n",
       "2                   where did the name rome come from?   \n",
       "3                 what does the name austin stand for?   \n",
       "4             where does the name melbourne come from?   \n",
       "...                                                ...   \n",
       "24913  what were some inventions of leonardo da vinci?   \n",
       "24914  what were some inventions of leonardo da vinci?   \n",
       "24915                  who is roger bacon inventor of?   \n",
       "24916    what did charles babbage create in the 1800s?   \n",
       "24917    what did charles babbage create in the 1800s?   \n",
       "\n",
       "                               prop  \n",
       "0      symbols.namesake.named_after  \n",
       "1      symbols.namesake.named_after  \n",
       "2      symbols.namesake.named_after  \n",
       "3      symbols.namesake.named_after  \n",
       "4      symbols.namesake.named_after  \n",
       "...                             ...  \n",
       "24913       law.inventor.inventions  \n",
       "24914       law.inventor.inventions  \n",
       "24915       law.inventor.inventions  \n",
       "24916       law.inventor.inventions  \n",
       "24917       law.inventor.inventions  \n",
       "\n",
       "[22132 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[['head', 'topic', 'sub', 'ans', 'target_text', 'prop']].drop_duplicates()\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa5284a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22132, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=train_df.iloc[  :35000,:]\n",
    "train_df=train_df.sample(frac = 1)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0a3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_of_batches=len(train_df)/batch_size\n",
    "num_of_epochs=4\n",
    "num_of_batches=int(num_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e743f50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:1\") \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af9a9949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
    "#moving the model to device(GPU/CPU)\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ff92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adafactor(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,\n",
    "    eps=(1e-30, 1e-3),\n",
    "    clip_threshold=1.0,\n",
    "    decay_rate=-0.8,\n",
    "    beta1=None,\n",
    "    weight_decay=0.0,\n",
    "    relative_step=False,\n",
    "    scale_parameter=False,\n",
    "    warmup_init=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4a544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def progress(loss,value, max=100):\n",
    "    return HTML(\"\"\" Batch loss :{loss}\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 100%'\n",
    "        >\n",
    "            {value}\n",
    "        </progress>\n",
    "    \"\"\".format(loss=loss,value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a71522",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f23db8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running epoch: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.08317184448242188\n",
       "        <progress\n",
       "            value='344'\n",
       "            max='346',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            344\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> what character did santa claus play?</s>\n",
      "<pad> what was johnnie barnes first name?</s>\n",
      "Epoch: 1 , Running loss: 0.21718351925196855\n",
      "\n",
      " Running epoch: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.067277692258358\n",
       "        <progress\n",
       "            value='344'\n",
       "            max='346',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            344\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> who was santa claus based on?</s>\n",
      "<pad> what position did johnnie barnes play?</s>\n",
      "Epoch: 2 , Running loss: 0.07400181365833766\n",
      "\n",
      " Running epoch: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.03765643388032913\n",
       "        <progress\n",
       "            value='344'\n",
       "            max='346',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            344\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> where is santa claus based?</s>\n",
      "<pad> what position did johnnie barnes play?</s>\n",
      "Epoch: 3 , Running loss: 0.053618909186427144\n",
      "\n",
      " Running epoch: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.025565356016159058\n",
       "        <progress\n",
       "            value='344'\n",
       "            max='346',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            344\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> what santa claus created?</s>\n",
      "<pad> what position did johnnie barnes play?</s>\n",
      "Epoch: 4 , Running loss: 0.043674658665406534\n"
     ]
    }
   ],
   "source": [
    "#Sets the module in training mode\n",
    "model.train()\n",
    "\n",
    "loss_per_10_steps=[]\n",
    "for epoch in range(1,num_of_epochs+1):\n",
    "\n",
    "    model.train()\n",
    "    print('\\n Running epoch: {}'.format(epoch))\n",
    "\n",
    "    running_loss=0\n",
    "\n",
    "    out = display(progress(1, num_of_batches+1), display_id=True)\n",
    "    for i in range(num_of_batches):\n",
    "        inputbatch=[]\n",
    "        labelbatch=[]\n",
    "        new_df=train_df[i*batch_size:i*batch_size+batch_size]\n",
    "        for indx,row in new_df.iterrows():\n",
    "            input = 'WQSP: '+ row['head']+' | '+row['topic']+ ' | '+row['sub'] + ' | '+row['ans'] + ' </s>' \n",
    "            labels = row['target_text']+'</s>' \n",
    "            inputbatch.append(input)\n",
    "            labelbatch.append(labels)\n",
    "        inputbatch=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=64,return_tensors='pt')[\"input_ids\"]\n",
    "        labelbatch=tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=64,return_tensors=\"pt\")[\"input_ids\"]\n",
    "        inputbatch=inputbatch.to(dev)\n",
    "        labelbatch=labelbatch.to(dev)\n",
    "\n",
    "        # clear out the gradients of all Variables \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propogation\n",
    "        outputs = model(input_ids=inputbatch, labels=labelbatch)\n",
    "        loss = outputs.loss\n",
    "        loss_num=loss.item()\n",
    "        logits = outputs.logits\n",
    "        running_loss+=loss_num\n",
    "        if i%10 ==0:\n",
    "            loss_per_10_steps.append(loss_num)\n",
    "        out.update(progress(loss_num,i, num_of_batches+1))\n",
    "\n",
    "        # calculating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #updating the params\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(\"WQSP: santa claus | fictional character | based on | saint nicholas </s>\", return_tensors=\"pt\")  # Batch size 1\n",
    "    input_ids=input_ids.to(dev)\n",
    "    outputs = model.generate(input_ids)\n",
    "    print(tokenizer.decode(outputs[0]))\n",
    "    model.eval()\n",
    "    input_ids = tokenizer.encode(\"WQSP: johnnie barnes | football player | position s | quarterback </s>\", return_tensors=\"pt\")  # Batch size 1\n",
    "    input_ids=input_ids.to(dev)\n",
    "    outputs = model.generate(input_ids)\n",
    "    print(tokenizer.decode(outputs[0]))\n",
    "\n",
    "    running_loss=running_loss/int(num_of_batches)\n",
    "    print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c57b8e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "steps = [i*100 for i in range(len(loss_per_10_steps))]\n",
    "  \n",
    "plt.plot(steps, loss_per_10_steps)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86d8a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop1 = pd.read_csv('../Data/Path_gen/1hop_triples.csv', sep='\\\\t', names=['s', 'p', 'o'], header = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29e3df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>m.0286f82</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02kdv5l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>m.02rygc4</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>m.011n6yxf</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>m.0gktl2l</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>m.09n9rnk</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.082gq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732100</th>\n",
       "      <td>m.05my74d</td>\n",
       "      <td>architecture.architect.structures_designed</td>\n",
       "      <td>m.02mv8x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732112</th>\n",
       "      <td>m.0dc5mhq</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732173</th>\n",
       "      <td>m.063z2by</td>\n",
       "      <td>organization.organization.geographic_scope</td>\n",
       "      <td>m.07ssc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732183</th>\n",
       "      <td>m.0b681_d</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732198</th>\n",
       "      <td>m.03gr9jh</td>\n",
       "      <td>film.film.genre</td>\n",
       "      <td>m.02822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223987 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  s                                           p          o\n",
       "73        m.0286f82                             film.film.genre  m.02kdv5l\n",
       "77        m.02rygc4                             film.film.genre    m.02822\n",
       "139      m.011n6yxf                             film.film.genre    m.02822\n",
       "147       m.0gktl2l                             film.film.genre    m.02822\n",
       "152       m.09n9rnk                             film.film.genre    m.082gq\n",
       "...             ...                                         ...        ...\n",
       "4732100   m.05my74d  architecture.architect.structures_designed   m.02mv8x\n",
       "4732112   m.0dc5mhq                             film.film.genre    m.02822\n",
       "4732173   m.063z2by  organization.organization.geographic_scope    m.07ssc\n",
       "4732183   m.0b681_d                             film.film.genre    m.02822\n",
       "4732198   m.03gr9jh                             film.film.genre    m.02822\n",
       "\n",
       "[223987 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hop1[hop1.p == 'law.invention.date_of_invention']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"../Data/Path_gen/unseen.pkl\", \"rb\") as f:\n",
    "    unseen = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e357c3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223987"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hop1.drop(hop1[~hop1.p.isin(unseen)].index, inplace = True)\n",
    "len(hop1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a641a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hop1_sample = hop1.groupby('p').sample(frac=1).reset_index(drop=True).groupby('p').head(5)\n",
    "len(hop1_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "909402fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanprop(p):\n",
    "    topic, sub = p.rsplit('.', 1)\n",
    "    _, topic = topic.rsplit('.', 1)\n",
    "    sub = sub.replace('_', ' ')\n",
    "    topic = topic.replace('_', ' ')\n",
    "    return topic, sub\n",
    "\n",
    "def get_question(input_text, max_length=64):\n",
    "    model.eval()\n",
    "    features = tokenizer([input_text], return_tensors='pt')\n",
    "    output = model.generate(input_ids=features['input_ids'].to(dev), \n",
    "               attention_mask=features['attention_mask'].to(dev),\n",
    "               max_length=max_length)\n",
    "    return tokenizer.decode(output[0])[6:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31b559de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [00:15<00:00,  9.06it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "qlines = []\n",
    "for r in tqdm(hop1_sample.iterrows(), total=hop1_sample.shape[0]):\n",
    "    s = r[1][0]\n",
    "    p = r[1][1]\n",
    "    o = r[1][2]\n",
    "    if s not in mid2name or o not in mid2name:\n",
    "        continue\n",
    "    topic, sub = cleanprop(p)\n",
    "    input_text = 'WQSP: '+ mid2name[s].lower() +' | '+ topic + ' | '+ sub + ' | '+ mid2name[o].lower()  + ' </s>'\n",
    "    output_text = get_question(input_text)\n",
    "\n",
    "    qlines.append((output_text, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403d8c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(qlines, columns=['QA', 'Rel']).drop_duplicates().dropna()\n",
    "df.to_csv('data/1hop-synth-t5-unseen-only-medium.csv')\n",
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}